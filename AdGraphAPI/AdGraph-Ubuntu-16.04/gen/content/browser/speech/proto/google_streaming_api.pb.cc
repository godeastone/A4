// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google_streaming_api.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "google_streaming_api.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/io/zero_copy_stream_impl_lite.h>
// @@protoc_insertion_point(includes)

namespace content {
namespace proto {
class SpeechRecognitionEventDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<SpeechRecognitionEvent> {
} _SpeechRecognitionEvent_default_instance_;
class SpeechRecognitionResultDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<SpeechRecognitionResult> {
} _SpeechRecognitionResult_default_instance_;
class SpeechRecognitionAlternativeDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<SpeechRecognitionAlternative> {
} _SpeechRecognitionAlternative_default_instance_;

namespace protobuf_google_5fstreaming_5fapi_2eproto {

PROTOBUF_CONSTEXPR_VAR ::google::protobuf::internal::ParseTableField
    const TableStruct::entries[] = {
  {0, 0, 0, ::google::protobuf::internal::kInvalidMask, 0, 0},
};

PROTOBUF_CONSTEXPR_VAR ::google::protobuf::internal::AuxillaryParseTableField
    const TableStruct::aux[] = {
  ::google::protobuf::internal::AuxillaryParseTableField(),
};
PROTOBUF_CONSTEXPR_VAR ::google::protobuf::internal::ParseTable const
    TableStruct::schema[] = {
  { NULL, NULL, 0, -1, -1, false },
  { NULL, NULL, 0, -1, -1, false },
  { NULL, NULL, 0, -1, -1, false },
};


void TableStruct::Shutdown() {
  _SpeechRecognitionEvent_default_instance_.Shutdown();
  _SpeechRecognitionResult_default_instance_.Shutdown();
  _SpeechRecognitionAlternative_default_instance_.Shutdown();
}

void TableStruct::InitDefaultsImpl() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::google::protobuf::internal::InitProtobufDefaults();
  _SpeechRecognitionEvent_default_instance_.DefaultConstruct();
  _SpeechRecognitionResult_default_instance_.DefaultConstruct();
  _SpeechRecognitionAlternative_default_instance_.DefaultConstruct();
}

void InitDefaults() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &TableStruct::InitDefaultsImpl);
}
void AddDescriptorsImpl() {
  InitDefaults();
  ::google::protobuf::internal::OnShutdown(&TableStruct::Shutdown);
}

void AddDescriptors() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &AddDescriptorsImpl);
}

}  // namespace protobuf_google_5fstreaming_5fapi_2eproto

bool SpeechRecognitionEvent_StatusCode_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 8:
      return true;
    default:
      return false;
  }
}

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const SpeechRecognitionEvent_StatusCode SpeechRecognitionEvent::STATUS_SUCCESS;
const SpeechRecognitionEvent_StatusCode SpeechRecognitionEvent::STATUS_NO_SPEECH;
const SpeechRecognitionEvent_StatusCode SpeechRecognitionEvent::STATUS_ABORTED;
const SpeechRecognitionEvent_StatusCode SpeechRecognitionEvent::STATUS_AUDIO_CAPTURE;
const SpeechRecognitionEvent_StatusCode SpeechRecognitionEvent::STATUS_NETWORK;
const SpeechRecognitionEvent_StatusCode SpeechRecognitionEvent::STATUS_NOT_ALLOWED;
const SpeechRecognitionEvent_StatusCode SpeechRecognitionEvent::STATUS_SERVICE_NOT_ALLOWED;
const SpeechRecognitionEvent_StatusCode SpeechRecognitionEvent::STATUS_BAD_GRAMMAR;
const SpeechRecognitionEvent_StatusCode SpeechRecognitionEvent::STATUS_LANGUAGE_NOT_SUPPORTED;
const SpeechRecognitionEvent_StatusCode SpeechRecognitionEvent::StatusCode_MIN;
const SpeechRecognitionEvent_StatusCode SpeechRecognitionEvent::StatusCode_MAX;
const int SpeechRecognitionEvent::StatusCode_ARRAYSIZE;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900
bool SpeechRecognitionEvent_EndpointerEventType_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
    case 3:
      return true;
    default:
      return false;
  }
}

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const SpeechRecognitionEvent_EndpointerEventType SpeechRecognitionEvent::START_OF_SPEECH;
const SpeechRecognitionEvent_EndpointerEventType SpeechRecognitionEvent::END_OF_SPEECH;
const SpeechRecognitionEvent_EndpointerEventType SpeechRecognitionEvent::END_OF_AUDIO;
const SpeechRecognitionEvent_EndpointerEventType SpeechRecognitionEvent::END_OF_UTTERANCE;
const SpeechRecognitionEvent_EndpointerEventType SpeechRecognitionEvent::EndpointerEventType_MIN;
const SpeechRecognitionEvent_EndpointerEventType SpeechRecognitionEvent::EndpointerEventType_MAX;
const int SpeechRecognitionEvent::EndpointerEventType_ARRAYSIZE;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SpeechRecognitionEvent::kStatusFieldNumber;
const int SpeechRecognitionEvent::kResultFieldNumber;
const int SpeechRecognitionEvent::kEndpointFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SpeechRecognitionEvent::SpeechRecognitionEvent()
  : ::google::protobuf::MessageLite(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_google_5fstreaming_5fapi_2eproto::InitDefaults();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:content.proto.SpeechRecognitionEvent)
}
SpeechRecognitionEvent::SpeechRecognitionEvent(const SpeechRecognitionEvent& from)
  : ::google::protobuf::MessageLite(),
      _internal_metadata_(NULL),
      _has_bits_(from._has_bits_),
      _cached_size_(0),
      result_(from.result_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::memcpy(&status_, &from.status_,
    static_cast<size_t>(reinterpret_cast<char*>(&endpoint_) -
    reinterpret_cast<char*>(&status_)) + sizeof(endpoint_));
  // @@protoc_insertion_point(copy_constructor:content.proto.SpeechRecognitionEvent)
}

void SpeechRecognitionEvent::SharedCtor() {
  _cached_size_ = 0;
  ::memset(&status_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&endpoint_) -
      reinterpret_cast<char*>(&status_)) + sizeof(endpoint_));
}

SpeechRecognitionEvent::~SpeechRecognitionEvent() {
  // @@protoc_insertion_point(destructor:content.proto.SpeechRecognitionEvent)
  SharedDtor();
}

void SpeechRecognitionEvent::SharedDtor() {
}

void SpeechRecognitionEvent::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const SpeechRecognitionEvent& SpeechRecognitionEvent::default_instance() {
  protobuf_google_5fstreaming_5fapi_2eproto::InitDefaults();
  return *internal_default_instance();
}

SpeechRecognitionEvent* SpeechRecognitionEvent::New(::google::protobuf::Arena* arena) const {
  SpeechRecognitionEvent* n = new SpeechRecognitionEvent;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void SpeechRecognitionEvent::Clear() {
// @@protoc_insertion_point(message_clear_start:content.proto.SpeechRecognitionEvent)
  result_.Clear();
  if (_has_bits_[0 / 32] & 3u) {
    ::memset(&status_, 0, static_cast<size_t>(
        reinterpret_cast<char*>(&endpoint_) -
        reinterpret_cast<char*>(&status_)) + sizeof(endpoint_));
  }
  _has_bits_.Clear();
  _internal_metadata_.Clear();
}

bool SpeechRecognitionEvent::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  ::google::protobuf::io::LazyStringOutputStream unknown_fields_string(
      ::google::protobuf::NewPermanentCallback(&_internal_metadata_,
          &::google::protobuf::internal::InternalMetadataWithArenaLite::
              mutable_unknown_fields));
  ::google::protobuf::io::CodedOutputStream unknown_fields_stream(
      &unknown_fields_string, false);
  // @@protoc_insertion_point(parse_start:content.proto.SpeechRecognitionEvent)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .content.proto.SpeechRecognitionEvent.StatusCode status = 1 [default = STATUS_SUCCESS];
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(8u)) {
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          if (::content::proto::SpeechRecognitionEvent_StatusCode_IsValid(value)) {
            set_status(static_cast< ::content::proto::SpeechRecognitionEvent_StatusCode >(value));
          } else {
            unknown_fields_stream.WriteVarint32(8u);
            unknown_fields_stream.WriteVarint32(
                static_cast< ::google::protobuf::uint32>(value));
          }
        } else {
          goto handle_unusual;
        }
        break;
      }

      // repeated .content.proto.SpeechRecognitionResult result = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(18u)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
                input, add_result()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // optional .content.proto.SpeechRecognitionEvent.EndpointerEventType endpoint = 4;
      case 4: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(32u)) {
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          if (::content::proto::SpeechRecognitionEvent_EndpointerEventType_IsValid(value)) {
            set_endpoint(static_cast< ::content::proto::SpeechRecognitionEvent_EndpointerEventType >(value));
          } else {
            unknown_fields_stream.WriteVarint32(32u);
            unknown_fields_stream.WriteVarint32(
                static_cast< ::google::protobuf::uint32>(value));
          }
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(
            input, tag, &unknown_fields_stream));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:content.proto.SpeechRecognitionEvent)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:content.proto.SpeechRecognitionEvent)
  return false;
#undef DO_
}

void SpeechRecognitionEvent::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:content.proto.SpeechRecognitionEvent)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // optional .content.proto.SpeechRecognitionEvent.StatusCode status = 1 [default = STATUS_SUCCESS];
  if (cached_has_bits & 0x00000001u) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      1, this->status(), output);
  }

  // repeated .content.proto.SpeechRecognitionResult result = 2;
  for (unsigned int i = 0,
      n = static_cast<unsigned int>(this->result_size()); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessage(
      2, this->result(static_cast<int>(i)), output);
  }

  // optional .content.proto.SpeechRecognitionEvent.EndpointerEventType endpoint = 4;
  if (cached_has_bits & 0x00000002u) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      4, this->endpoint(), output);
  }

  output->WriteRaw(unknown_fields().data(),
                   static_cast<int>(unknown_fields().size()));
  // @@protoc_insertion_point(serialize_end:content.proto.SpeechRecognitionEvent)
}

size_t SpeechRecognitionEvent::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:content.proto.SpeechRecognitionEvent)
  size_t total_size = 0;

  total_size += unknown_fields().size();

  // repeated .content.proto.SpeechRecognitionResult result = 2;
  {
    unsigned int count = static_cast<unsigned int>(this->result_size());
    total_size += 1UL * count;
    for (unsigned int i = 0; i < count; i++) {
      total_size +=
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          this->result(static_cast<int>(i)));
    }
  }

  if (_has_bits_[0 / 32] & 3u) {
    // optional .content.proto.SpeechRecognitionEvent.StatusCode status = 1 [default = STATUS_SUCCESS];
    if (has_status()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::EnumSize(this->status());
    }

    // optional .content.proto.SpeechRecognitionEvent.EndpointerEventType endpoint = 4;
    if (has_endpoint()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::EnumSize(this->endpoint());
    }

  }
  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void SpeechRecognitionEvent::CheckTypeAndMergeFrom(
    const ::google::protobuf::MessageLite& from) {
  MergeFrom(*::google::protobuf::down_cast<const SpeechRecognitionEvent*>(&from));
}

void SpeechRecognitionEvent::MergeFrom(const SpeechRecognitionEvent& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:content.proto.SpeechRecognitionEvent)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  result_.MergeFrom(from.result_);
  cached_has_bits = from._has_bits_[0];
  if (cached_has_bits & 3u) {
    if (cached_has_bits & 0x00000001u) {
      status_ = from.status_;
    }
    if (cached_has_bits & 0x00000002u) {
      endpoint_ = from.endpoint_;
    }
    _has_bits_[0] |= cached_has_bits;
  }
}

void SpeechRecognitionEvent::CopyFrom(const SpeechRecognitionEvent& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:content.proto.SpeechRecognitionEvent)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SpeechRecognitionEvent::IsInitialized() const {
  return true;
}

void SpeechRecognitionEvent::Swap(SpeechRecognitionEvent* other) {
  if (other == this) return;
  InternalSwap(other);
}
void SpeechRecognitionEvent::InternalSwap(SpeechRecognitionEvent* other) {
  result_.InternalSwap(&other->result_);
  std::swap(status_, other->status_);
  std::swap(endpoint_, other->endpoint_);
  std::swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::std::string SpeechRecognitionEvent::GetTypeName() const {
  return "content.proto.SpeechRecognitionEvent";
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// SpeechRecognitionEvent

// optional .content.proto.SpeechRecognitionEvent.StatusCode status = 1 [default = STATUS_SUCCESS];
bool SpeechRecognitionEvent::has_status() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
void SpeechRecognitionEvent::set_has_status() {
  _has_bits_[0] |= 0x00000001u;
}
void SpeechRecognitionEvent::clear_has_status() {
  _has_bits_[0] &= ~0x00000001u;
}
void SpeechRecognitionEvent::clear_status() {
  status_ = 0;
  clear_has_status();
}
::content::proto::SpeechRecognitionEvent_StatusCode SpeechRecognitionEvent::status() const {
  // @@protoc_insertion_point(field_get:content.proto.SpeechRecognitionEvent.status)
  return static_cast< ::content::proto::SpeechRecognitionEvent_StatusCode >(status_);
}
void SpeechRecognitionEvent::set_status(::content::proto::SpeechRecognitionEvent_StatusCode value) {
  assert(::content::proto::SpeechRecognitionEvent_StatusCode_IsValid(value));
  set_has_status();
  status_ = value;
  // @@protoc_insertion_point(field_set:content.proto.SpeechRecognitionEvent.status)
}

// repeated .content.proto.SpeechRecognitionResult result = 2;
int SpeechRecognitionEvent::result_size() const {
  return result_.size();
}
void SpeechRecognitionEvent::clear_result() {
  result_.Clear();
}
const ::content::proto::SpeechRecognitionResult& SpeechRecognitionEvent::result(int index) const {
  // @@protoc_insertion_point(field_get:content.proto.SpeechRecognitionEvent.result)
  return result_.Get(index);
}
::content::proto::SpeechRecognitionResult* SpeechRecognitionEvent::mutable_result(int index) {
  // @@protoc_insertion_point(field_mutable:content.proto.SpeechRecognitionEvent.result)
  return result_.Mutable(index);
}
::content::proto::SpeechRecognitionResult* SpeechRecognitionEvent::add_result() {
  // @@protoc_insertion_point(field_add:content.proto.SpeechRecognitionEvent.result)
  return result_.Add();
}
::google::protobuf::RepeatedPtrField< ::content::proto::SpeechRecognitionResult >*
SpeechRecognitionEvent::mutable_result() {
  // @@protoc_insertion_point(field_mutable_list:content.proto.SpeechRecognitionEvent.result)
  return &result_;
}
const ::google::protobuf::RepeatedPtrField< ::content::proto::SpeechRecognitionResult >&
SpeechRecognitionEvent::result() const {
  // @@protoc_insertion_point(field_list:content.proto.SpeechRecognitionEvent.result)
  return result_;
}

// optional .content.proto.SpeechRecognitionEvent.EndpointerEventType endpoint = 4;
bool SpeechRecognitionEvent::has_endpoint() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
void SpeechRecognitionEvent::set_has_endpoint() {
  _has_bits_[0] |= 0x00000002u;
}
void SpeechRecognitionEvent::clear_has_endpoint() {
  _has_bits_[0] &= ~0x00000002u;
}
void SpeechRecognitionEvent::clear_endpoint() {
  endpoint_ = 0;
  clear_has_endpoint();
}
::content::proto::SpeechRecognitionEvent_EndpointerEventType SpeechRecognitionEvent::endpoint() const {
  // @@protoc_insertion_point(field_get:content.proto.SpeechRecognitionEvent.endpoint)
  return static_cast< ::content::proto::SpeechRecognitionEvent_EndpointerEventType >(endpoint_);
}
void SpeechRecognitionEvent::set_endpoint(::content::proto::SpeechRecognitionEvent_EndpointerEventType value) {
  assert(::content::proto::SpeechRecognitionEvent_EndpointerEventType_IsValid(value));
  set_has_endpoint();
  endpoint_ = value;
  // @@protoc_insertion_point(field_set:content.proto.SpeechRecognitionEvent.endpoint)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SpeechRecognitionResult::kAlternativeFieldNumber;
const int SpeechRecognitionResult::kFinalFieldNumber;
const int SpeechRecognitionResult::kStabilityFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SpeechRecognitionResult::SpeechRecognitionResult()
  : ::google::protobuf::MessageLite(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_google_5fstreaming_5fapi_2eproto::InitDefaults();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:content.proto.SpeechRecognitionResult)
}
SpeechRecognitionResult::SpeechRecognitionResult(const SpeechRecognitionResult& from)
  : ::google::protobuf::MessageLite(),
      _internal_metadata_(NULL),
      _has_bits_(from._has_bits_),
      _cached_size_(0),
      alternative_(from.alternative_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::memcpy(&final_, &from.final_,
    static_cast<size_t>(reinterpret_cast<char*>(&stability_) -
    reinterpret_cast<char*>(&final_)) + sizeof(stability_));
  // @@protoc_insertion_point(copy_constructor:content.proto.SpeechRecognitionResult)
}

void SpeechRecognitionResult::SharedCtor() {
  _cached_size_ = 0;
  ::memset(&final_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&stability_) -
      reinterpret_cast<char*>(&final_)) + sizeof(stability_));
}

SpeechRecognitionResult::~SpeechRecognitionResult() {
  // @@protoc_insertion_point(destructor:content.proto.SpeechRecognitionResult)
  SharedDtor();
}

void SpeechRecognitionResult::SharedDtor() {
}

void SpeechRecognitionResult::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const SpeechRecognitionResult& SpeechRecognitionResult::default_instance() {
  protobuf_google_5fstreaming_5fapi_2eproto::InitDefaults();
  return *internal_default_instance();
}

SpeechRecognitionResult* SpeechRecognitionResult::New(::google::protobuf::Arena* arena) const {
  SpeechRecognitionResult* n = new SpeechRecognitionResult;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void SpeechRecognitionResult::Clear() {
// @@protoc_insertion_point(message_clear_start:content.proto.SpeechRecognitionResult)
  alternative_.Clear();
  if (_has_bits_[0 / 32] & 3u) {
    ::memset(&final_, 0, static_cast<size_t>(
        reinterpret_cast<char*>(&stability_) -
        reinterpret_cast<char*>(&final_)) + sizeof(stability_));
  }
  _has_bits_.Clear();
  _internal_metadata_.Clear();
}

bool SpeechRecognitionResult::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  ::google::protobuf::io::LazyStringOutputStream unknown_fields_string(
      ::google::protobuf::NewPermanentCallback(&_internal_metadata_,
          &::google::protobuf::internal::InternalMetadataWithArenaLite::
              mutable_unknown_fields));
  ::google::protobuf::io::CodedOutputStream unknown_fields_stream(
      &unknown_fields_string, false);
  // @@protoc_insertion_point(parse_start:content.proto.SpeechRecognitionResult)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .content.proto.SpeechRecognitionAlternative alternative = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
                input, add_alternative()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // optional bool final = 2 [default = false];
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(16u)) {
          set_has_final();
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &final_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // optional float stability = 3;
      case 3: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(29u)) {
          set_has_stability();
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   float, ::google::protobuf::internal::WireFormatLite::TYPE_FLOAT>(
                 input, &stability_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(
            input, tag, &unknown_fields_stream));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:content.proto.SpeechRecognitionResult)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:content.proto.SpeechRecognitionResult)
  return false;
#undef DO_
}

void SpeechRecognitionResult::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:content.proto.SpeechRecognitionResult)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // repeated .content.proto.SpeechRecognitionAlternative alternative = 1;
  for (unsigned int i = 0,
      n = static_cast<unsigned int>(this->alternative_size()); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessage(
      1, this->alternative(static_cast<int>(i)), output);
  }

  cached_has_bits = _has_bits_[0];
  // optional bool final = 2 [default = false];
  if (cached_has_bits & 0x00000001u) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(2, this->final(), output);
  }

  // optional float stability = 3;
  if (cached_has_bits & 0x00000002u) {
    ::google::protobuf::internal::WireFormatLite::WriteFloat(3, this->stability(), output);
  }

  output->WriteRaw(unknown_fields().data(),
                   static_cast<int>(unknown_fields().size()));
  // @@protoc_insertion_point(serialize_end:content.proto.SpeechRecognitionResult)
}

size_t SpeechRecognitionResult::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:content.proto.SpeechRecognitionResult)
  size_t total_size = 0;

  total_size += unknown_fields().size();

  // repeated .content.proto.SpeechRecognitionAlternative alternative = 1;
  {
    unsigned int count = static_cast<unsigned int>(this->alternative_size());
    total_size += 1UL * count;
    for (unsigned int i = 0; i < count; i++) {
      total_size +=
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          this->alternative(static_cast<int>(i)));
    }
  }

  if (_has_bits_[0 / 32] & 3u) {
    // optional bool final = 2 [default = false];
    if (has_final()) {
      total_size += 1 + 1;
    }

    // optional float stability = 3;
    if (has_stability()) {
      total_size += 1 + 4;
    }

  }
  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void SpeechRecognitionResult::CheckTypeAndMergeFrom(
    const ::google::protobuf::MessageLite& from) {
  MergeFrom(*::google::protobuf::down_cast<const SpeechRecognitionResult*>(&from));
}

void SpeechRecognitionResult::MergeFrom(const SpeechRecognitionResult& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:content.proto.SpeechRecognitionResult)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  alternative_.MergeFrom(from.alternative_);
  cached_has_bits = from._has_bits_[0];
  if (cached_has_bits & 3u) {
    if (cached_has_bits & 0x00000001u) {
      final_ = from.final_;
    }
    if (cached_has_bits & 0x00000002u) {
      stability_ = from.stability_;
    }
    _has_bits_[0] |= cached_has_bits;
  }
}

void SpeechRecognitionResult::CopyFrom(const SpeechRecognitionResult& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:content.proto.SpeechRecognitionResult)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SpeechRecognitionResult::IsInitialized() const {
  return true;
}

void SpeechRecognitionResult::Swap(SpeechRecognitionResult* other) {
  if (other == this) return;
  InternalSwap(other);
}
void SpeechRecognitionResult::InternalSwap(SpeechRecognitionResult* other) {
  alternative_.InternalSwap(&other->alternative_);
  std::swap(final_, other->final_);
  std::swap(stability_, other->stability_);
  std::swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::std::string SpeechRecognitionResult::GetTypeName() const {
  return "content.proto.SpeechRecognitionResult";
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// SpeechRecognitionResult

// repeated .content.proto.SpeechRecognitionAlternative alternative = 1;
int SpeechRecognitionResult::alternative_size() const {
  return alternative_.size();
}
void SpeechRecognitionResult::clear_alternative() {
  alternative_.Clear();
}
const ::content::proto::SpeechRecognitionAlternative& SpeechRecognitionResult::alternative(int index) const {
  // @@protoc_insertion_point(field_get:content.proto.SpeechRecognitionResult.alternative)
  return alternative_.Get(index);
}
::content::proto::SpeechRecognitionAlternative* SpeechRecognitionResult::mutable_alternative(int index) {
  // @@protoc_insertion_point(field_mutable:content.proto.SpeechRecognitionResult.alternative)
  return alternative_.Mutable(index);
}
::content::proto::SpeechRecognitionAlternative* SpeechRecognitionResult::add_alternative() {
  // @@protoc_insertion_point(field_add:content.proto.SpeechRecognitionResult.alternative)
  return alternative_.Add();
}
::google::protobuf::RepeatedPtrField< ::content::proto::SpeechRecognitionAlternative >*
SpeechRecognitionResult::mutable_alternative() {
  // @@protoc_insertion_point(field_mutable_list:content.proto.SpeechRecognitionResult.alternative)
  return &alternative_;
}
const ::google::protobuf::RepeatedPtrField< ::content::proto::SpeechRecognitionAlternative >&
SpeechRecognitionResult::alternative() const {
  // @@protoc_insertion_point(field_list:content.proto.SpeechRecognitionResult.alternative)
  return alternative_;
}

// optional bool final = 2 [default = false];
bool SpeechRecognitionResult::has_final() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
void SpeechRecognitionResult::set_has_final() {
  _has_bits_[0] |= 0x00000001u;
}
void SpeechRecognitionResult::clear_has_final() {
  _has_bits_[0] &= ~0x00000001u;
}
void SpeechRecognitionResult::clear_final() {
  final_ = false;
  clear_has_final();
}
bool SpeechRecognitionResult::final() const {
  // @@protoc_insertion_point(field_get:content.proto.SpeechRecognitionResult.final)
  return final_;
}
void SpeechRecognitionResult::set_final(bool value) {
  set_has_final();
  final_ = value;
  // @@protoc_insertion_point(field_set:content.proto.SpeechRecognitionResult.final)
}

// optional float stability = 3;
bool SpeechRecognitionResult::has_stability() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
void SpeechRecognitionResult::set_has_stability() {
  _has_bits_[0] |= 0x00000002u;
}
void SpeechRecognitionResult::clear_has_stability() {
  _has_bits_[0] &= ~0x00000002u;
}
void SpeechRecognitionResult::clear_stability() {
  stability_ = 0;
  clear_has_stability();
}
float SpeechRecognitionResult::stability() const {
  // @@protoc_insertion_point(field_get:content.proto.SpeechRecognitionResult.stability)
  return stability_;
}
void SpeechRecognitionResult::set_stability(float value) {
  set_has_stability();
  stability_ = value;
  // @@protoc_insertion_point(field_set:content.proto.SpeechRecognitionResult.stability)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SpeechRecognitionAlternative::kTranscriptFieldNumber;
const int SpeechRecognitionAlternative::kConfidenceFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SpeechRecognitionAlternative::SpeechRecognitionAlternative()
  : ::google::protobuf::MessageLite(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_google_5fstreaming_5fapi_2eproto::InitDefaults();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:content.proto.SpeechRecognitionAlternative)
}
SpeechRecognitionAlternative::SpeechRecognitionAlternative(const SpeechRecognitionAlternative& from)
  : ::google::protobuf::MessageLite(),
      _internal_metadata_(NULL),
      _has_bits_(from._has_bits_),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  transcript_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (from.has_transcript()) {
    transcript_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.transcript_);
  }
  confidence_ = from.confidence_;
  // @@protoc_insertion_point(copy_constructor:content.proto.SpeechRecognitionAlternative)
}

void SpeechRecognitionAlternative::SharedCtor() {
  _cached_size_ = 0;
  transcript_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  confidence_ = 0;
}

SpeechRecognitionAlternative::~SpeechRecognitionAlternative() {
  // @@protoc_insertion_point(destructor:content.proto.SpeechRecognitionAlternative)
  SharedDtor();
}

void SpeechRecognitionAlternative::SharedDtor() {
  transcript_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}

void SpeechRecognitionAlternative::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const SpeechRecognitionAlternative& SpeechRecognitionAlternative::default_instance() {
  protobuf_google_5fstreaming_5fapi_2eproto::InitDefaults();
  return *internal_default_instance();
}

SpeechRecognitionAlternative* SpeechRecognitionAlternative::New(::google::protobuf::Arena* arena) const {
  SpeechRecognitionAlternative* n = new SpeechRecognitionAlternative;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void SpeechRecognitionAlternative::Clear() {
// @@protoc_insertion_point(message_clear_start:content.proto.SpeechRecognitionAlternative)
  if (has_transcript()) {
    GOOGLE_DCHECK(!transcript_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()));
    (*transcript_.UnsafeRawStringPointer())->clear();
  }
  confidence_ = 0;
  _has_bits_.Clear();
  _internal_metadata_.Clear();
}

bool SpeechRecognitionAlternative::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  ::google::protobuf::io::LazyStringOutputStream unknown_fields_string(
      ::google::protobuf::NewPermanentCallback(&_internal_metadata_,
          &::google::protobuf::internal::InternalMetadataWithArenaLite::
              mutable_unknown_fields));
  ::google::protobuf::io::CodedOutputStream unknown_fields_stream(
      &unknown_fields_string, false);
  // @@protoc_insertion_point(parse_start:content.proto.SpeechRecognitionAlternative)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional string transcript = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_transcript()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // optional float confidence = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(21u)) {
          set_has_confidence();
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   float, ::google::protobuf::internal::WireFormatLite::TYPE_FLOAT>(
                 input, &confidence_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(
            input, tag, &unknown_fields_stream));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:content.proto.SpeechRecognitionAlternative)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:content.proto.SpeechRecognitionAlternative)
  return false;
#undef DO_
}

void SpeechRecognitionAlternative::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:content.proto.SpeechRecognitionAlternative)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // optional string transcript = 1;
  if (cached_has_bits & 0x00000001u) {
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->transcript(), output);
  }

  // optional float confidence = 2;
  if (cached_has_bits & 0x00000002u) {
    ::google::protobuf::internal::WireFormatLite::WriteFloat(2, this->confidence(), output);
  }

  output->WriteRaw(unknown_fields().data(),
                   static_cast<int>(unknown_fields().size()));
  // @@protoc_insertion_point(serialize_end:content.proto.SpeechRecognitionAlternative)
}

size_t SpeechRecognitionAlternative::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:content.proto.SpeechRecognitionAlternative)
  size_t total_size = 0;

  total_size += unknown_fields().size();

  if (_has_bits_[0 / 32] & 3u) {
    // optional string transcript = 1;
    if (has_transcript()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::StringSize(
          this->transcript());
    }

    // optional float confidence = 2;
    if (has_confidence()) {
      total_size += 1 + 4;
    }

  }
  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void SpeechRecognitionAlternative::CheckTypeAndMergeFrom(
    const ::google::protobuf::MessageLite& from) {
  MergeFrom(*::google::protobuf::down_cast<const SpeechRecognitionAlternative*>(&from));
}

void SpeechRecognitionAlternative::MergeFrom(const SpeechRecognitionAlternative& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:content.proto.SpeechRecognitionAlternative)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._has_bits_[0];
  if (cached_has_bits & 3u) {
    if (cached_has_bits & 0x00000001u) {
      set_has_transcript();
      transcript_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.transcript_);
    }
    if (cached_has_bits & 0x00000002u) {
      confidence_ = from.confidence_;
    }
    _has_bits_[0] |= cached_has_bits;
  }
}

void SpeechRecognitionAlternative::CopyFrom(const SpeechRecognitionAlternative& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:content.proto.SpeechRecognitionAlternative)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SpeechRecognitionAlternative::IsInitialized() const {
  return true;
}

void SpeechRecognitionAlternative::Swap(SpeechRecognitionAlternative* other) {
  if (other == this) return;
  InternalSwap(other);
}
void SpeechRecognitionAlternative::InternalSwap(SpeechRecognitionAlternative* other) {
  transcript_.Swap(&other->transcript_);
  std::swap(confidence_, other->confidence_);
  std::swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::std::string SpeechRecognitionAlternative::GetTypeName() const {
  return "content.proto.SpeechRecognitionAlternative";
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// SpeechRecognitionAlternative

// optional string transcript = 1;
bool SpeechRecognitionAlternative::has_transcript() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
void SpeechRecognitionAlternative::set_has_transcript() {
  _has_bits_[0] |= 0x00000001u;
}
void SpeechRecognitionAlternative::clear_has_transcript() {
  _has_bits_[0] &= ~0x00000001u;
}
void SpeechRecognitionAlternative::clear_transcript() {
  transcript_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_transcript();
}
const ::std::string& SpeechRecognitionAlternative::transcript() const {
  // @@protoc_insertion_point(field_get:content.proto.SpeechRecognitionAlternative.transcript)
  return transcript_.GetNoArena();
}
void SpeechRecognitionAlternative::set_transcript(const ::std::string& value) {
  set_has_transcript();
  transcript_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:content.proto.SpeechRecognitionAlternative.transcript)
}
#if LANG_CXX11
void SpeechRecognitionAlternative::set_transcript(::std::string&& value) {
  set_has_transcript();
  transcript_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:content.proto.SpeechRecognitionAlternative.transcript)
}
#endif
void SpeechRecognitionAlternative::set_transcript(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_transcript();
  transcript_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:content.proto.SpeechRecognitionAlternative.transcript)
}
void SpeechRecognitionAlternative::set_transcript(const char* value, size_t size) {
  set_has_transcript();
  transcript_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:content.proto.SpeechRecognitionAlternative.transcript)
}
::std::string* SpeechRecognitionAlternative::mutable_transcript() {
  set_has_transcript();
  // @@protoc_insertion_point(field_mutable:content.proto.SpeechRecognitionAlternative.transcript)
  return transcript_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
::std::string* SpeechRecognitionAlternative::release_transcript() {
  // @@protoc_insertion_point(field_release:content.proto.SpeechRecognitionAlternative.transcript)
  clear_has_transcript();
  return transcript_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
void SpeechRecognitionAlternative::set_allocated_transcript(::std::string* transcript) {
  if (transcript != NULL) {
    set_has_transcript();
  } else {
    clear_has_transcript();
  }
  transcript_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), transcript);
  // @@protoc_insertion_point(field_set_allocated:content.proto.SpeechRecognitionAlternative.transcript)
}

// optional float confidence = 2;
bool SpeechRecognitionAlternative::has_confidence() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
void SpeechRecognitionAlternative::set_has_confidence() {
  _has_bits_[0] |= 0x00000002u;
}
void SpeechRecognitionAlternative::clear_has_confidence() {
  _has_bits_[0] &= ~0x00000002u;
}
void SpeechRecognitionAlternative::clear_confidence() {
  confidence_ = 0;
  clear_has_confidence();
}
float SpeechRecognitionAlternative::confidence() const {
  // @@protoc_insertion_point(field_get:content.proto.SpeechRecognitionAlternative.confidence)
  return confidence_;
}
void SpeechRecognitionAlternative::set_confidence(float value) {
  set_has_confidence();
  confidence_ = value;
  // @@protoc_insertion_point(field_set:content.proto.SpeechRecognitionAlternative.confidence)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace proto
}  // namespace content

// @@protoc_insertion_point(global_scope)
